# Phase 0-4 Minimal Delivery Package
## Exact Files & Folders Needed to Complete All Phases

**Purpose:** Send to another person's PC to execute phases 0â†’4 without the entire project  
**Total Package Size:** ~5-8 GB (mostly data)  
**Timeline:** 5-6 days compute time  

---

## ğŸ“¦ FOLDER STRUCTURE (Minimal)

```
ids-compression-benchmark/
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ pytorch_fixed_full/              â† REQUIRED: Base model checkpoint
â”œâ”€â”€ data/
â”‚   â””â”€â”€ splits/                          â† REQUIRED: Training/validation data
â”œâ”€â”€ models/
â”‚   â””â”€â”€ lstm_ids_v2.py                  â† NEW: Phase 2 LSTM architecture
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ phase0_per_class_analysis.py    â† PHASE 0: Diagnostic analysis
â”‚   â”œâ”€â”€ phase1_improvements.py           â† PHASE 1: Improvement utilities
â”‚   â”œâ”€â”€ train_phase1_improved.py         â† PHASE 1: Training script
â”‚   â”œâ”€â”€ train_phase2_lstm.py             â† PHASE 2: LSTM training
â”‚   â”œâ”€â”€ phase3_ensemble.py               â† PHASE 3: Ensemble utilities
â”‚   â”œâ”€â”€ train_phase3_ensemble.py         â† PHASE 3: Ensemble optimization
â”‚   â””â”€â”€ orchestrate_training.py          â† OPTIONAL: Run all phases at once
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ kd_config.yaml                  â† Config files (optional but recommended)
â”‚   â”œâ”€â”€ canonical_schema.yaml
â”‚   â””â”€â”€ class_weights.json
â”œâ”€â”€ results/                             â† OUTPUT: Will be created automatically
â”œâ”€â”€ environment.yml                      â† Python environment
â”œâ”€â”€ requirements.txt                     â† Python dependencies
â””â”€â”€ PHASE0-4_EXECUTION_GUIDE.md         â† Instructions (this file)
```

---

## ğŸ“‹ FILES TO COPY (Detailed Checklist)

### âœ… **MUST-COPY SECTION**

#### 1. **Checkpoints Directory** `checkpoints/pytorch_fixed_full/`
These are the base model and training data for all phases.

```
checkpoints/pytorch_fixed_full/
â”œâ”€â”€ best_model.pt              âœ“ REQUIRED - Base CNN checkpoint (88.17% F1)
â”œâ”€â”€ validation_data.pt         âœ“ REQUIRED - Validation set for phase 0 analysis
â””â”€â”€ (optional: checkpoint_epoch_*.pt if you want all intermediate checkpoints)
```

**Size:** ~500 MB  
**Purpose:** Phase 0 loads this model to analyze per-class failures

---

#### 2. **Data Splits Directory** `data/splits/`
These are the training and validation datasets for phases 1-3.

```
data/splits/
â”œâ”€â”€ train.parquet              âœ“ REQUIRED - Training set (~76M samples)
â”œâ”€â”€ val.parquet                âœ“ REQUIRED - Validation set (~balanced)
â””â”€â”€ split_manifest.json        âœ“ REQUIRED - Metadata about splits
```

**Size:** ~4-5 GB  
**Purpose:** Phases 1, 2, 3 use this for retraining and evaluation  
**NOTE:** These files are LARGE. If bandwidth limited, ask for compressed archive.

---

#### 3. **Script Files** `scripts/`
The Python scripts for each phase.

```
scripts/
â”œâ”€â”€ phase0_per_class_analysis.py         âœ“ REQUIRED
â”œâ”€â”€ phase1_improvements.py               âœ“ REQUIRED
â”œâ”€â”€ train_phase1_improved.py             âœ“ REQUIRED
â”œâ”€â”€ train_phase2_lstm.py                 âœ“ REQUIRED
â”œâ”€â”€ phase3_ensemble.py                   âœ“ REQUIRED
â”œâ”€â”€ train_phase3_ensemble.py             âœ“ REQUIRED
â””â”€â”€ orchestrate_training.py              âœ“ OPTIONAL (convenience script)
```

**Size:** ~1-2 MB  
**Purpose:** Phase 0-4 execution scripts

---

#### 4. **Models Directory** `models/`
The LSTM architecture (new in phases 2+).

```
models/
â”œâ”€â”€ lstm_ids_v2.py                       âœ“ REQUIRED
â””â”€â”€ __init__.py                          âœ“ REQUIRED (just copy as-is)
```

**Size:** <1 MB  
**Purpose:** LSTM model definition for phase 2

---

#### 5. **Config Files** `configs/`
Optional but recommended for consistency.

```
configs/
â”œâ”€â”€ kd_config.yaml                       âœ“ RECOMMENDED
â”œâ”€â”€ canonical_schema.yaml                âœ“ RECOMMENDED
â”œâ”€â”€ class_weights.json                   âœ“ RECOMMENDED
â””â”€â”€ (others can be skipped)
```

**Size:** <1 MB  
**Purpose:** Reference configurations

---

#### 6. **Environment & Dependencies**
```
â”œâ”€â”€ requirements.txt                     âœ“ REQUIRED - Python packages
â”œâ”€â”€ environment.yml                      âœ“ REQUIRED - Conda environment (if using conda)
```

**Purpose:** Install dependencies with `pip install -r requirements.txt`

---

### âš ï¸ **DO NOT COPY** (Will Be Created)

The following will be generated automatically - no need to copy:

```
results/                                 â† Auto-created, will store outputs
â”œâ”€â”€ phase0_analysis/                    â† Phase 0 analysis results
â”œâ”€â”€ phase1_improved_model/               â† Phase 1 trained model
â”œâ”€â”€ phase2_lstm_model/                   â† Phase 2 trained model
â””â”€â”€ phase3_ensemble/                     â† Phase 3 ensemble config
```

---

## ğŸš€ EXECUTION SEQUENCE

### **PHASE 0: Diagnostic Analysis** (4 hours)
```bash
python scripts/phase0_per_class_analysis.py
```
**Input:** `checkpoints/pytorch_fixed_full/best_model.pt` + `validation_data.pt`  
**Output:** Per-class metrics, confusion matrix, failure patterns  
**Expected:** Identifies which classes drag down F1

---

### **PHASE 1: CNN Improvements** (1-2 days)
```bash
python scripts/train_phase1_improved.py
```
**Input:** Base CNN checkpoint + training data  
**Output:** Improved CNN checkpoint (88.9-89.5% F1)  
**Expected:** Mixup + Temperature scaling + Threshold tuning

---

### **PHASE 2: LSTM Training** (1-2 days)
```bash
python scripts/train_phase2_lstm.py
```
**Input:** Training data (LSTM expects same format as CNN)  
**Output:** LSTM checkpoint (~89.0-89.8% F1)  
**Expected:** Bidirectional LSTM with temporal feature learning  
**Note:** Can run in parallel with Phase 1 if using separate GPU

---

### **PHASE 3: Ensemble Optimization** (2-3 hours)
```bash
python scripts/train_phase3_ensemble.py
```
**Input:** Phase 1 CNN checkpoint + Phase 2 LSTM checkpoint  
**Output:** Ensemble configuration (90.0-91.0% F1) âœ“ TARGET  
**Expected:** Optimized weights and temperatures for both models

---

### **PHASE 4: Statistical Validation** (1 hour, optional)
```bash
# To be executed if phase4_statistical_validation.py is created
# Provides: Bootstrap confidence intervals, statistical tests
```

---

## ğŸ“Š EXPECTED RESULTS

| Phase | Expected F1 | Gain | Output |
|-------|------------|------|--------|
| Baseline (Phase 0) | 88.17% | â€” | Analysis report |
| Phase 1 | 88.9-89.5% | +0.73-1.33% | Improved CNN checkpoint |
| Phase 2 | 89.0-89.8% | +0.83-1.63% | LSTM checkpoint |
| Phase 3 | 90.0-91.0% | +0.83-2.83% | Ensemble config âœ“ |
| Phase 4 | â€” | â€” | Statistical tables |

---

## ğŸ’¾ DATASET DETAILS

### **Training Data** `data/splits/train.parquet`
- **Samples:** ~76 million (balanced, 5000 per class Ã— 15+ classes)
- **Features:** 41 NetFlow features
- **Format:** Parquet (compressed)
- **Size:** ~3-4 GB

### **Validation Data** `data/splits/val.parquet`
- **Samples:** ~Balanced (1000+ per class)
- **Features:** 41 NetFlow features (same as training)
- **Format:** Parquet
- **Size:** ~1-2 GB

### **Also in Checkpoint**
- `checkpoints/pytorch_fixed_full/validation_data.pt` - Pre-loaded validation set for Phase 0
- **Size:** ~1 GB (same data, different format for faster loading)

---

## âš™ï¸ SYSTEM REQUIREMENTS

### **Minimum**
- **RAM:** 16 GB (for data loading)
- **GPU:** Optional but strongly recommended (10+ GB VRAM)
  - Without GPU: Phase 1-3 will take 3-5x longer
  - With GPU (RTX 3090 or better): 1-2 days total
- **Disk:** 20 GB free (for model checkpoints + results)
- **Python:** 3.8+

### **Recommended**
- **RAM:** 32 GB
- **GPU:** RTX 3090 / A100 (20+ GB VRAM)
- **Disk:** 50 GB free

---

## ğŸ“¥ QUICK SETUP CHECKLIST

1. **Copy all folders** from above checklist to new PC
   ```
   checkpoints/
   data/
   models/
   scripts/
   configs/
   requirements.txt
   environment.yml
   ```

2. **Create Python environment**
   ```bash
   # Option A: Using pip
   pip install -r requirements.txt
   
   # Option B: Using conda
   conda env create -f environment.yml
   conda activate ids-benchmark
   ```

3. **Verify checkpoint exists**
   ```bash
   ls checkpoints/pytorch_fixed_full/best_model.pt
   ls data/splits/train.parquet
   ```

4. **Run Phase 0**
   ```bash
   cd scripts
   python phase0_per_class_analysis.py
   ```

5. **Follow console output** - should see progress bars and results

---

## ğŸ”§ TROUBLESHOOTING

### **"best_model.pt not found"**
- Ensure `checkpoints/pytorch_fixed_full/` directory is copied
- Check file permissions (should be readable)

### **"train.parquet not found"**
- Ensure `data/splits/` directory is copied
- This file is ~3-4 GB, may take time to transfer

### **CUDA out of memory**
- Reduce `BATCH_SIZE` in phase scripts (line ~40-50)
- Change from 256 â†’ 128 or 64
- Or run on CPU (slower but will work)

### **"Module not found" errors**
- Run `pip install -r requirements.txt` again
- Verify installation: `python -c "import torch; print(torch.__version__)"`

---

## ğŸ“ SUPPORT

If issues arise, provide:
1. **Error message** (full traceback)
2. **System specs** (GPU type, RAM, Python version)
3. **Phase number** (0, 1, 2, 3, or 4)
4. **Output from** `python scripts/phase0_per_class_analysis.py` (first 50 lines)

---

## ğŸ“ FILE CHECKSUMS (Optional Verification)

If bandwidth concerns, verify downloads:

```bash
# After copying, verify critical files
ls -lh checkpoints/pytorch_fixed_full/best_model.pt
ls -lh data/splits/train.parquet
ls -lh data/splits/val.parquet

# Check total size
du -sh checkpoints/
du -sh data/
du -sh models/
du -sh scripts/
```

Expected:
- `best_model.pt`: ~500 MB
- `train.parquet`: ~3-4 GB
- `val.parquet`: ~1-2 GB
- Total: ~5-8 GB

---

## âœ… FINAL CHECKLIST BEFORE SENDING

- [ ] `checkpoints/pytorch_fixed_full/best_model.pt` copied
- [ ] `checkpoints/pytorch_fixed_full/validation_data.pt` copied
- [ ] `data/splits/train.parquet` copied
- [ ] `data/splits/val.parquet` copied
- [ ] `data/splits/split_manifest.json` copied
- [ ] `scripts/phase0_per_class_analysis.py` copied
- [ ] `scripts/phase1_improvements.py` copied
- [ ] `scripts/train_phase1_improved.py` copied
- [ ] `scripts/train_phase2_lstm.py` copied
- [ ] `scripts/phase3_ensemble.py` copied
- [ ] `scripts/train_phase3_ensemble.py` copied
- [ ] `scripts/orchestrate_training.py` copied (optional)
- [ ] `models/lstm_ids_v2.py` copied
- [ ] `models/__init__.py` copied
- [ ] `requirements.txt` copied
- [ ] `environment.yml` copied
- [ ] `configs/kd_config.yaml` copied (recommended)

---

**Status:** Ready to Ship âœ…  
**Created:** December 27, 2025  
**Phases Covered:** 0 â†’ 1 â†’ 2 â†’ 3 â†’ 4

